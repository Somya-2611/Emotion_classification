{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":115439,"databundleVersionId":13800781,"sourceType":"competition"},{"sourceId":662619,"sourceType":"modelInstanceVersion","modelInstanceId":501337,"modelId":516518},{"sourceId":662657,"sourceType":"modelInstanceVersion","modelInstanceId":501337,"modelId":516518},{"sourceId":666534,"sourceType":"modelInstanceVersion","modelInstanceId":504533,"modelId":519508},{"sourceId":666563,"sourceType":"modelInstanceVersion","modelInstanceId":504554,"modelId":519526}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom transformers import AutoTokenizer\nimport kagglehub\nimport wandb\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-30T17:30:50.180300Z","iopub.execute_input":"2025-11-30T17:30:50.180524Z","iopub.status.idle":"2025-11-30T17:31:01.358111Z","shell.execute_reply.started":"2025-11-30T17:30:50.180499Z","shell.execute_reply":"2025-11-30T17:31:01.357363Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/emotion-classifier/pytorch/v1/3/emotion_classifier.pth\n/kaggle/input/emotion-classifier/pytorch/v1/3/best_model.pt\n/kaggle/input/emotion-classifier/pytorch/v1/1/emotion_classifier.pth\n/kaggle/input/debertafull/pytorch/v1/1/spm.model\n/kaggle/input/debertafull/pytorch/v1/1/config.json\n/kaggle/input/debertafull/pytorch/v1/1/training_args.bin\n/kaggle/input/debertafull/pytorch/v1/1/tokenizer.json\n/kaggle/input/debertafull/pytorch/v1/1/tokenizer_config.json\n/kaggle/input/debertafull/pytorch/v1/1/model.safetensors\n/kaggle/input/debertafull/pytorch/v1/1/special_tokens_map.json\n/kaggle/input/debertafull/pytorch/v1/1/added_tokens.json\n/kaggle/input/roberta-emotion/pytorch/v1/1/model.pth\n/kaggle/input/2025-sep-dl-gen-ai-project/sample_submission.csv\n/kaggle/input/2025-sep-dl-gen-ai-project/train.csv\n/kaggle/input/2025-sep-dl-gen-ai-project/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/2025-sep-dl-gen-ai-project/train.csv')\ntest = pd.read_csv('/kaggle/input/2025-sep-dl-gen-ai-project/test.csv')\nsample = pd.read_csv(\"/kaggle/input/2025-sep-dl-gen-ai-project/sample_submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T17:31:06.679054Z","iopub.execute_input":"2025-11-30T17:31:06.679668Z","iopub.status.idle":"2025-11-30T17:31:06.732293Z","shell.execute_reply.started":"2025-11-30T17:31:06.679642Z","shell.execute_reply":"2025-11-30T17:31:06.731822Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T17:31:08.550040Z","iopub.execute_input":"2025-11-30T17:31:08.550565Z","iopub.status.idle":"2025-11-30T17:31:08.572345Z","shell.execute_reply.started":"2025-11-30T17:31:08.550540Z","shell.execute_reply":"2025-11-30T17:31:08.571558Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   id                                               text  anger  fear  joy  \\\n0   0  the dentist that did the work apparently did a...      1     0    0   \n1   1  i'm gonna absolutely ~~suck~~ be terrible duri...      0     1    0   \n2   2  bridge: so leave me drowning calling houston, ...      0     1    0   \n3   3  after that mess i went to see my now ex-girlfr...      1     1    0   \n4   4  as he stumbled i ran off, afraid it might some...      0     1    0   \n\n   sadness  surprise                    emotions  \n0        1         0         ['anger' 'sadness']  \n1        1         0          ['fear' 'sadness']  \n2        1         0          ['fear' 'sadness']  \n3        1         0  ['anger' 'fear' 'sadness']  \n4        0         0                    ['fear']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>anger</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>emotions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>the dentist that did the work apparently did a...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>['anger' 'sadness']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>i'm gonna absolutely ~~suck~~ be terrible duri...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>['fear' 'sadness']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>bridge: so leave me drowning calling houston, ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>['fear' 'sadness']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>after that mess i went to see my now ex-girlfr...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>['anger' 'fear' 'sadness']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>as he stumbled i ran off, afraid it might some...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['fear']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"test.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T12:41:18.033426Z","iopub.execute_input":"2025-11-30T12:41:18.033703Z","iopub.status.idle":"2025-11-30T12:41:18.041039Z","shell.execute_reply.started":"2025-11-30T12:41:18.033680Z","shell.execute_reply":"2025-11-30T12:41:18.040183Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   id                                               text\n0   0  she wanted to fight over every single little t...\n1   1                           anyway, back to tuesday.\n2   2                she shrieked at the dog to go back.\n3   3  yelling for everyone to get back or get inside...\n4   4                              still kind of freaky.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>she wanted to fight over every single little t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>anyway, back to tuesday.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>she shrieked at the dog to go back.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>yelling for everyone to get back or get inside...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>still kind of freaky.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:14:01.943096Z","iopub.execute_input":"2025-11-29T05:14:01.943729Z","iopub.status.idle":"2025-11-29T05:14:01.947684Z","shell.execute_reply.started":"2025-11-29T05:14:01.943701Z","shell.execute_reply":"2025-11-29T05:14:01.947093Z"}},"outputs":[{"name":"stdout","text":"(6827, 8)\n(1707, 2)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# **EDA** ","metadata":{}},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = train.iloc[:,2:7].sum()\nrowsums = train.iloc[:, 2:7].sum(axis=1) # take label columns and sum it column wise\nno_label_count = 0 \nfor i, count in rowsums.items():     \n\tif count==0:         \n\t\tno_label_count += 1          \nprint('Total number of rows:', len(train)) \nprint('Total number of rows without labels(emotions):', no_label_count) \t\nprint('Total labels:', x.sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(6, 4))\nax = sns.barplot(x=x.index, y=x.values, alpha=0.8, palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:brown', 'tab:red', 'tab:grey'])\nplt.title('Label Counts')\nplt.ylabel('Count')\nplt.xlabel('Emotion')\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nax = sns.countplot(x=rowsums.values, alpha=0.8, palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:brown', 'tab:red', 'tab:grey'])\nplt.title('Emotions per Row')\nplt.ylabel('# of Occurences')\nplt.xlabel('# of Labels')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.iloc[6750,1]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **DEBERTA V3 BASE(0.804)**","metadata":{}},{"cell_type":"code","source":"# # Imports & seed setup\n# import os\n# import random\n# import numpy as np\n# import pandas as pd\n# import torch\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import f1_score\n# from datasets import Dataset\n# from transformers import (\n#     AutoTokenizer,\n#     AutoModelForSequenceClassification,\n#     DataCollatorWithPadding,\n#     TrainingArguments,\n#     Trainer,\n#     set_seed\n# )\n\n\n# # Reproducibility\n# SEED = 42\n# set_seed(SEED)\n# random.seed(SEED)\n# np.random.seed(SEED)\n# torch.manual_seed(SEED)\n# if torch.cuda.is_available():\n#     torch.cuda.manual_seed_all(SEED)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:07:17.970329Z","iopub.execute_input":"2025-11-30T15:07:17.970603Z","iopub.status.idle":"2025-11-30T15:07:38.064947Z","shell.execute_reply.started":"2025-11-30T15:07:17.970578Z","shell.execute_reply":"2025-11-30T15:07:38.064432Z"}},"outputs":[{"name":"stderr","text":"2025-11-30 15:07:20.375937: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764515240.566280      38 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764515240.625652      38 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# wandb.login(key = \"1cae1eb0b3009c258573b649b577124df891befe\" , relogin=True) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:07:47.582538Z","iopub.execute_input":"2025-11-30T15:07:47.583458Z","iopub.status.idle":"2025-11-30T15:07:53.848149Z","shell.execute_reply.started":"2025-11-30T15:07:47.583434Z","shell.execute_reply":"2025-11-30T15:07:53.847593Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msomya108\u001b[0m (\u001b[33mdlproject_sept2025\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# train_df = pd.read_csv('/kaggle/input/2025-sep-dl-gen-ai-project/train.csv')\n# test_df = pd.read_csv('/kaggle/input/2025-sep-dl-gen-ai-project/test.csv')\n\n\n# label_cols = ['anger','fear','joy','sadness','surprise']\n# train_df[label_cols] = train_df[label_cols].astype(int)\n\n# train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=SEED, shuffle=True)\n# train_df = train_df.reset_index(drop=True)\n# val_df   = val_df.reset_index(drop=True)\n\n# # Create HuggingFace Datasets\n# hf_train = Dataset.from_pandas(train_df[['id','text'] + label_cols])\n# hf_val   = Dataset.from_pandas(val_df[['id','text'] + label_cols])\n# hf_test  = Dataset.from_pandas(test_df[['id','text']])\n\n# def add_labels(example):\n#     example[\"labels\"] = [float(example[c]) for c in label_cols]  # <-- float\n#     return example\n\n# hf_train = hf_train.map(add_labels)\n# hf_val   = hf_val.map(add_labels)\n\n\n\n# MODEL_NAME = \"microsoft/deberta-v3-base\"\n# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n# MAX_LENGTH = 256\n\n# def tokenize(batch):\n#     return tokenizer(batch[\"text\"], truncation=True, padding=False, max_length=MAX_LENGTH)\n\n# hf_train = hf_train.map(tokenize, batched=True)\n# hf_val   = hf_val.map(tokenize, batched=True)\n# hf_test  = hf_test.map(tokenize, batched=True)\n\n\n# hf_train = hf_train.remove_columns(label_cols)\n# hf_val   = hf_val.remove_columns(label_cols)\n\n\n# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:21:55.939498Z","iopub.execute_input":"2025-11-30T15:21:55.940309Z","iopub.status.idle":"2025-11-30T15:21:59.300836Z","shell.execute_reply.started":"2025-11-30T15:21:55.940263Z","shell.execute_reply":"2025-11-30T15:21:59.300126Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6144 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c2b80433d0d42d8a9144f946cd911a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/683 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c71fafe6d49f49a19c09d56e4ca0a12b"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6144 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d89849a19154c0ca086684579f096cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/683 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a4d20a1bcfb49778c4cadd5316593cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1707 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4400a9096b470890e53e72685cf95d"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# model = AutoModelForSequenceClassification.from_pretrained(\n#     MODEL_NAME,\n#     num_labels=len(label_cols),\n#     problem_type=\"multi_label_classification\"\n# )\n\n# def compute_metrics(eval_pred):\n#     logits, labels = eval_pred\n#     probs = torch.sigmoid(torch.tensor(logits))\n#     preds = (probs > 0.5).int().numpy()\n#     labels = labels.astype(int)\n#     macro_f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n#     per_label_f1 = f1_score(labels, preds, average=None, zero_division=0).tolist()\n#     return {\n#         \"macro_f1\": macro_f1,\n#         \"f1_anger\": per_label_f1[0],\n#         \"f1_fear\": per_label_f1[1],\n#         \"f1_joy\": per_label_f1[2],\n#         \"f1_sadness\": per_label_f1[3],\n#         \"f1_surprise\": per_label_f1[4],\n#     }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:22:02.140578Z","iopub.execute_input":"2025-11-30T15:22:02.140845Z","iopub.status.idle":"2025-11-30T15:22:02.926634Z","shell.execute_reply.started":"2025-11-30T15:22:02.140826Z","shell.execute_reply":"2025-11-30T15:22:02.925956Z"}},"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# training_args = TrainingArguments(\n#     output_dir=\"./deberta_v3_base_emotion\",\n\n#     per_device_train_batch_size=8,\n#     per_device_eval_batch_size=16,\n#     gradient_accumulation_steps=1,\n\n#     learning_rate=2e-5,\n#     weight_decay=0.01,\n#     num_train_epochs=3,\n\n#     eval_strategy=\"steps\",\n#     save_strategy=\"steps\",\n#     eval_steps=500,\n#     save_steps=500,\n#     logging_steps=100,\n\n#     load_best_model_at_end=True,\n#     metric_for_best_model=\"macro_f1\",\n\n#     save_total_limit=2,\n#     fp16=True if torch.cuda.is_available() else False,\n#     seed=SEED,\n\n#     report_to=\"wandb\",     \n#     run_name=\"DeBERTa-v3-emotion\", \n    \n# )\n\n# wandb.init(project=\"23f1001420-t32025\", name=\"deberta-v3-base\") \n\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=hf_train,\n#     eval_dataset=hf_val,\n#     tokenizer=tokenizer,\n#     data_collator=data_collator,\n#     compute_metrics=compute_metrics,\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:22:05.890512Z","iopub.execute_input":"2025-11-30T15:22:05.890782Z","iopub.status.idle":"2025-11-30T15:22:13.646911Z","shell.execute_reply.started":"2025-11-30T15:22:05.890762Z","shell.execute_reply":"2025-11-30T15:22:13.646192Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251130_152205-yph9lv95</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/yph9lv95' target=\"_blank\">deberta-v3-base</a></strong> to <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/yph9lv95' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/yph9lv95</a>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_38/362676207.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# trainer.train()\n# trainer.save_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:22:25.949506Z","iopub.execute_input":"2025-11-30T15:22:25.949744Z","iopub.status.idle":"2025-11-30T15:29:03.967862Z","shell.execute_reply.started":"2025-11-30T15:22:25.949729Z","shell.execute_reply":"2025-11-30T15:29:03.967065Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1152' max='1152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1152/1152 06:34, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Macro F1</th>\n      <th>F1 Anger</th>\n      <th>F1 Fear</th>\n      <th>F1 Joy</th>\n      <th>F1 Sadness</th>\n      <th>F1 Surprise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.302200</td>\n      <td>0.295517</td>\n      <td>0.752987</td>\n      <td>0.569106</td>\n      <td>0.853567</td>\n      <td>0.764706</td>\n      <td>0.780723</td>\n      <td>0.796834</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.215900</td>\n      <td>0.246335</td>\n      <td>0.824202</td>\n      <td>0.733333</td>\n      <td>0.879899</td>\n      <td>0.800000</td>\n      <td>0.845794</td>\n      <td>0.861985</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# wandb.finish()  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:29:08.522315Z","iopub.execute_input":"2025-11-30T15:29:08.522590Z","iopub.status.idle":"2025-11-30T15:29:09.003032Z","shell.execute_reply.started":"2025-11-30T15:29:08.522572Z","shell.execute_reply":"2025-11-30T15:29:09.002525Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1_anger</td><td>▁█</td></tr><tr><td>eval/f1_fear</td><td>▁█</td></tr><tr><td>eval/f1_joy</td><td>▁█</td></tr><tr><td>eval/f1_sadness</td><td>▁█</td></tr><tr><td>eval/f1_surprise</td><td>▁█</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/macro_f1</td><td>▁█</td></tr><tr><td>eval/runtime</td><td>▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▄▅▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▄▄▄▅▆▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▂▃▁▂▅▃▃█▅▆▃</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▅▅▄▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▃▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1_anger</td><td>0.73333</td></tr><tr><td>eval/f1_fear</td><td>0.8799</td></tr><tr><td>eval/f1_joy</td><td>0.8</td></tr><tr><td>eval/f1_sadness</td><td>0.84579</td></tr><tr><td>eval/f1_surprise</td><td>0.86199</td></tr><tr><td>eval/loss</td><td>0.24633</td></tr><tr><td>eval/macro_f1</td><td>0.8242</td></tr><tr><td>eval/runtime</td><td>3.1268</td></tr><tr><td>eval/samples_per_second</td><td>218.434</td></tr><tr><td>eval/steps_per_second</td><td>7.036</td></tr><tr><td>total_flos</td><td>491201046055104.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>1152</td></tr><tr><td>train/grad_norm</td><td>149111.60938</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1981</td></tr><tr><td>train_loss</td><td>0.31189</td></tr><tr><td>train_runtime</td><td>395.311</td></tr><tr><td>train_samples_per_second</td><td>46.627</td></tr><tr><td>train_steps_per_second</td><td>2.914</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">deberta-v3-base</strong> at: <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/yph9lv95' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/yph9lv95</a><br> View project at: <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251130_152205-yph9lv95/logs</code>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# save_dir = \"deberta_full_model\"\n# os.makedirs(save_dir, exist_ok=True)\n\n# # Save HF model\n# trainer.save_model(save_dir)\n\n# # Save tokenizer\n# tokenizer.save_pretrained(save_dir)\n\n# print(\"Saved full model folder:\", os.listdir(save_dir))\n# user = \"somya2611\"\n# Deberta_handle = f\"{user}/DebertaFull/pyTorch/v1\"\n\n# kagglehub.model_upload(Deberta_handle, \"deberta_full_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:01:40.959989Z","iopub.execute_input":"2025-11-30T06:01:40.960515Z","iopub.status.idle":"2025-11-30T06:01:58.522245Z","shell.execute_reply.started":"2025-11-30T06:01:40.960489Z","shell.execute_reply":"2025-11-30T06:01:58.521650Z"}},"outputs":[{"name":"stdout","text":"Saved full model folder: ['training_args.bin', 'spm.model', 'special_tokens_map.json', 'model.safetensors', 'tokenizer.json', 'added_tokens.json', 'tokenizer_config.json', 'config.json']\nUploading Model https://www.kaggle.com/models/somya2611/DebertaFull/pyTorch/v1 ...\nModel 'DebertaFull' does not exist or access is forbidden for user 'somya2611'. Creating or handling Model...\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\nModel 'DebertaFull' Created.\nStarting upload for file deberta_full_model/training_args.bin\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 5.30k/5.30k [00:00<00:00, 14.1kB/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: deberta_full_model/training_args.bin (5KB)\nStarting upload for file deberta_full_model/spm.model\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 2.46M/2.46M [00:00<00:00, 5.41MB/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: deberta_full_model/spm.model (2MB)\nStarting upload for file deberta_full_model/special_tokens_map.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 286/286 [00:00<00:00, 759B/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: deberta_full_model/special_tokens_map.json (286B)\nStarting upload for file deberta_full_model/model.safetensors\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 738M/738M [00:06<00:00, 116MB/s]  ","output_type":"stream"},{"name":"stdout","text":"Upload successful: deberta_full_model/model.safetensors (704MB)\nStarting upload for file deberta_full_model/tokenizer.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 8.66M/8.66M [00:00<00:00, 18.2MB/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: deberta_full_model/tokenizer.json (8MB)\nStarting upload for file deberta_full_model/added_tokens.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 23.0/23.0 [00:00<00:00, 57.3B/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: deberta_full_model/added_tokens.json (23B)\nStarting upload for file deberta_full_model/tokenizer_config.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 1.31k/1.31k [00:00<00:00, 3.38kB/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: deberta_full_model/tokenizer_config.json (1KB)\nStarting upload for file deberta_full_model/config.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 1.13k/1.13k [00:00<00:00, 2.94kB/s]","output_type":"stream"},{"name":"stdout","text":"Upload successful: deberta_full_model/config.json (1KB)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\nYour model instance has been created.\nFiles are being processed...\nSee at: https://www.kaggle.com/models/somya2611/DebertaFull/pyTorch/v1\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# user = \"somya2611\"\n# Deberta_handle = f\"{user}/DebertaFull/pyTorch/v1\"\n\n# model_folder = kagglehub.model_download(Deberta_handle)\n# print(\"Files downloaded:\", os.listdir(model_folder))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:02:30.740501Z","iopub.execute_input":"2025-11-30T06:02:30.740820Z","iopub.status.idle":"2025-11-30T06:02:44.920151Z","shell.execute_reply.started":"2025-11-30T06:02:30.740785Z","shell.execute_reply":"2025-11-30T06:02:44.919543Z"}},"outputs":[{"name":"stdout","text":"Files downloaded: ['spm.model', 'config.json', 'training_args.bin', 'tokenizer.json', 'tokenizer_config.json', 'model.safetensors', 'special_tokens_map.json', 'added_tokens.json']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# tokenizer = AutoTokenizer.from_pretrained(model_folder)\n\n# model = AutoModelForSequenceClassification.from_pretrained(\n#     model_folder,\n#     problem_type=\"multi_label_classification\"\n# ).to(device)\n\n# model.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:03:00.906120Z","iopub.execute_input":"2025-11-30T06:03:00.906415Z","iopub.status.idle":"2025-11-30T06:03:08.265181Z","shell.execute_reply.started":"2025-11-30T06:03:00.906394Z","shell.execute_reply":"2025-11-30T06:03:08.264528Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# inference_trainer = Trainer(\n#     model=model,\n#     tokenizer=tokenizer,\n#     data_collator=data_collator\n# )\n\n# preds = inference_trainer.predict(hf_test)\n# logits = preds.predictions\n# probs = torch.sigmoid(torch.tensor(logits)).numpy()\n# binary_preds = (probs > 0.5).astype(int)\n\n\n# submission = pd.DataFrame(binary_preds, columns=label_cols)\n# submission.insert(0, \"id\", test_df[\"id\"].values)\n\n# submission.to_csv(\"submission.csv\", index=False)\n# print(\"Saved submission.csv\")\n# submission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:03:12.896633Z","iopub.execute_input":"2025-11-30T06:03:12.897184Z","iopub.status.idle":"2025-11-30T06:03:24.388250Z","shell.execute_reply.started":"2025-11-30T06:03:12.897159Z","shell.execute_reply":"2025-11-30T06:03:24.387657Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_38/3727258776.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  inference_trainer = Trainer(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Saved submission.csv\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   id  anger  fear  joy  sadness  surprise\n0   0      1     1    0        0         0\n1   1      0     0    0        0         0\n2   2      1     0    0        0         0\n3   3      0     1    0        0         0\n4   4      0     1    0        0         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anger</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **ROBERTA(0.81)**","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# import torch\n# import torch.nn as nn\n# from torch.utils.data import Dataset, DataLoader\n# from sklearn.model_selection import train_test_split\n# from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n# from tqdm import tqdm\n\n# train.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:38:34.983012Z","iopub.execute_input":"2025-11-30T15:38:34.983739Z","iopub.status.idle":"2025-11-30T15:38:34.993709Z","shell.execute_reply.started":"2025-11-30T15:38:34.983715Z","shell.execute_reply":"2025-11-30T15:38:34.992928Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   id                                               text  anger  fear  joy  \\\n0   0  the dentist that did the work apparently did a...      1     0    0   \n1   1  i'm gonna absolutely ~~suck~~ be terrible duri...      0     1    0   \n2   2  bridge: so leave me drowning calling houston, ...      0     1    0   \n3   3  after that mess i went to see my now ex-girlfr...      1     1    0   \n4   4  as he stumbled i ran off, afraid it might some...      0     1    0   \n\n   sadness  surprise                    emotions  \n0        1         0         ['anger' 'sadness']  \n1        1         0          ['fear' 'sadness']  \n2        1         0          ['fear' 'sadness']  \n3        1         0  ['anger' 'fear' 'sadness']  \n4        0         0                    ['fear']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>anger</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>emotions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>the dentist that did the work apparently did a...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>['anger' 'sadness']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>i'm gonna absolutely ~~suck~~ be terrible duri...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>['fear' 'sadness']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>bridge: so leave me drowning calling houston, ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>['fear' 'sadness']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>after that mess i went to see my now ex-girlfr...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>['anger' 'fear' 'sadness']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>as he stumbled i ran off, afraid it might some...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['fear']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# wandb.login(key = \"1cae1eb0b3009c258573b649b577124df891befe\" , relogin=True) \n\n# wandb.init(\n#     project=\"23f1001420-t32025\",   \n#     name=\"roberta_trainer\", \n#     config={\n#         \"model_name\": \"roberta-base\",\n#         \"batch_size\": 16,\n#         \"lr\": 2e-5,\n#         \"epochs\": 3,\n#         \"max_len\": 128\n#     }\n# )\n# config = wandb.config   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:38:38.866273Z","iopub.execute_input":"2025-11-30T15:38:38.866988Z","iopub.status.idle":"2025-11-30T15:38:45.739802Z","shell.execute_reply.started":"2025-11-30T15:38:38.866962Z","shell.execute_reply":"2025-11-30T15:38:45.739086Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251130_153838-ktkaynui</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/ktkaynui' target=\"_blank\">roberta_trainer</a></strong> to <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/ktkaynui' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/ktkaynui</a>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"label_cols = [\"anger\",\"fear\",\"joy\",\"sadness\",\"surprise\"]\n\nX_train, X_val = train_test_split(train, test_size=0.1, random_state=42, shuffle=True)\nclass EmotionDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=128, is_train=True):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.is_train = is_train\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        text = str(row[\"text\"])\n\n        enc = self.tokenizer(\n            text,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n\n        if self.is_train:\n            labels = torch.tensor(row[label_cols].values.astype('float32'))\n            return enc.input_ids.squeeze(), enc.attention_mask.squeeze(), labels\n        else:\n            return enc.input_ids.squeeze(), enc.attention_mask.squeeze()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:38:52.528950Z","iopub.execute_input":"2025-11-30T15:38:52.529213Z","iopub.status.idle":"2025-11-30T15:38:52.539071Z","shell.execute_reply.started":"2025-11-30T15:38:52.529195Z","shell.execute_reply":"2025-11-30T15:38:52.538492Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# class EmotionClassifier(nn.Module):\n#     def __init__(self, model_name=\"roberta-base\", dropout=0.3):\n#         super().__init__()\n#         self.encoder = AutoModel.from_pretrained(model_name)\n#         self.dropout = nn.Dropout(dropout)\n#         self.fc = nn.Linear(self.encoder.config.hidden_size, 5)\n    \n#     def forward(self, input_ids, attention_mask):\n#         out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n#         pooled = out.last_hidden_state[:,0]  # CLS token\n#         x = self.dropout(pooled)\n#         return self.fc(x)\n\n\n# tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n\n# train_ds = EmotionDataset(X_train, tokenizer, is_train=True)\n# val_ds   = EmotionDataset(X_val, tokenizer, is_train=True)\n# test_ds  = EmotionDataset(test, tokenizer, is_train=False)\n\n# train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n# val_loader   = DataLoader(val_ds, batch_size=16, shuffle=False)\n# test_loader  = DataLoader(test_ds, batch_size=16, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:38:54.865822Z","iopub.execute_input":"2025-11-30T15:38:54.866499Z","iopub.status.idle":"2025-11-30T15:38:56.066314Z","shell.execute_reply.started":"2025-11-30T15:38:54.866476Z","shell.execute_reply":"2025-11-30T15:38:56.065501Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a86496ed9ff4569a53857c33579bab5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5990993f62b486fae25b93565838336"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c122685d6d32421091d56a4d9a24ddf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b00320ac21a24f358a4470012c03c7f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0629438fa23f4774a01c5c0771be99c7"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# model = EmotionClassifier().to(device)\n# criterion = nn.BCEWithLogitsLoss()\n\n# optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)   # ⭐ changed to wandb config\n# epochs = config.epochs\n\n# total_steps = len(train_loader) * epochs\n\n# scheduler = get_linear_schedule_with_warmup(\n#     optimizer,\n#     num_warmup_steps=int(0.1 * total_steps),\n#     num_training_steps=total_steps\n# )\n\n# def train_model():\n#     for epoch in range(epochs):\n#         model.train()\n#         total_loss = 0\n\n#         for batch in tqdm(train_loader):\n#             input_ids, attention_mask, labels = [b.to(device) for b in batch]\n            \n#             optimizer.zero_grad()\n#             outputs = model(input_ids, attention_mask)\n#             loss = criterion(outputs, labels)\n#             loss.backward()\n#             optimizer.step()\n#             scheduler.step()\n\n#             total_loss += loss.item()\n#             wandb.log({\"batch_loss\": loss.item()}) \n\n#         epoch_loss = total_loss / len(train_loader)\n#         print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")\n\n#         wandb.log({\"train_epoch_loss\": epoch_loss})\n        \n#         validate(epoch)\n\n# def validate(epoch):\n#     model.eval()\n#     preds_list = []\n#     true_list = []\n\n#     with torch.no_grad():\n#         for batch in val_loader:\n#             input_ids, attention_mask, labels = [b.to(device) for b in batch]\n#             outputs = model(input_ids, attention_mask)\n#             preds = torch.sigmoid(outputs).cpu().numpy()\n#             preds_list.append(preds)\n#             true_list.append(labels.cpu().numpy())\n\n#     preds_list = np.vstack(preds_list)\n#     true_list = np.vstack(true_list)\n\n#     # Macro F1 calculation across 5 labels\n#     from sklearn.metrics import f1_score\n#     binary_preds = (preds_list > 0.5).astype(int)\n#     f1 = f1_score(true_list, binary_preds, average=\"macro\")\n#     print(\"Validation Macro F1:\", f1)\n#     wandb.log({\"val_macro_f1\": f1}) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:42:55.990860Z","iopub.execute_input":"2025-11-30T15:42:55.991460Z","iopub.status.idle":"2025-11-30T15:42:56.318775Z","shell.execute_reply.started":"2025-11-30T15:42:55.991439Z","shell.execute_reply":"2025-11-30T15:42:56.318028Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# train_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:43:10.126059Z","iopub.execute_input":"2025-11-30T15:43:10.126489Z","iopub.status.idle":"2025-11-30T15:50:20.706177Z","shell.execute_reply.started":"2025-11-30T15:43:10.126460Z","shell.execute_reply":"2025-11-30T15:50:20.705499Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 384/384 [02:14<00:00,  2.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3 - Loss: 0.4598\nValidation Macro F1: 0.7568219698520873\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [02:19<00:00,  2.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/3 - Loss: 0.2780\nValidation Macro F1: 0.7852946232423269\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 384/384 [02:21<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/3 - Loss: 0.1998\nValidation Macro F1: 0.8228246844548435\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# wandb.finish() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T15:50:27.227289Z","iopub.execute_input":"2025-11-30T15:50:27.227547Z","iopub.status.idle":"2025-11-30T15:50:27.630783Z","shell.execute_reply.started":"2025-11-30T15:50:27.227529Z","shell.execute_reply":"2025-11-30T15:50:27.630290Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>▇█▆▄▇▅▃▂▄▂▄▆▆▅▅▄▆▄▄▄▅▅▃▄▃▃▃▂▃▂▁▁▁▃▂▂▁▁▂▂</td></tr><tr><td>train_epoch_loss</td><td>█▃▁</td></tr><tr><td>val_macro_f1</td><td>▁▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.16326</td></tr><tr><td>train_epoch_loss</td><td>0.19982</td></tr><tr><td>val_macro_f1</td><td>0.82282</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">roberta_trainer</strong> at: <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/ktkaynui' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/ktkaynui</a><br> View project at: <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251130_153838-ktkaynui/logs</code>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# save_dir = \"roberta_emotion_model\"\n# os.makedirs(save_dir, exist_ok=True)\n\n# model_path = os.path.join(save_dir, \"model.pth\")\n# torch.save(model.state_dict(), model_path)\n# print(\"Saved:\", model_path)\n\n# user = \"somya2611\"\n# upload_handle = f\"{user}/roberta-emotion/pyTorch/v1\"\n\n# kagglehub.model_upload(upload_handle, \"roberta_emotion_model\")\n\n# print(\"Model uploaded to:\", upload_handle)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:23:32.506736Z","iopub.execute_input":"2025-11-30T06:23:32.507465Z","iopub.status.idle":"2025-11-30T06:23:40.139467Z","shell.execute_reply.started":"2025-11-30T06:23:32.507441Z","shell.execute_reply":"2025-11-30T06:23:40.138943Z"}},"outputs":[{"name":"stdout","text":"Saved: roberta_emotion_model/model.pth\nUploading Model https://www.kaggle.com/models/somya2611/roberta-emotion/pyTorch/v1 ...\nModel 'roberta-emotion' does not exist or access is forbidden for user 'somya2611'. Creating or handling Model...\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\nModel 'roberta-emotion' Created.\nStarting upload for file roberta_emotion_model/model.pth\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n","output_type":"stream"},{"name":"stderr","text":"Uploading: 100%|██████████| 499M/499M [00:04<00:00, 118MB/s]  ","output_type":"stream"},{"name":"stdout","text":"Upload successful: roberta_emotion_model/model.pth (476MB)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\nYour model instance has been created.\nFiles are being processed...\nSee at: https://www.kaggle.com/models/somya2611/roberta-emotion/pyTorch/v1\nModel uploaded to: somya2611/roberta-emotion/pyTorch/v1\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# user = \"somya2611\"\n# download_handle = f\"{user}/roberta-emotion/pyTorch/v1\"\n\n# model_folder = kagglehub.model_download(download_handle)\n# print(\"Downloaded model folder:\", model_folder)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:24:07.628451Z","iopub.execute_input":"2025-11-30T06:24:07.629013Z","iopub.status.idle":"2025-11-30T06:24:23.377794Z","shell.execute_reply.started":"2025-11-30T06:24:07.628988Z","shell.execute_reply":"2025-11-30T06:24:23.377080Z"}},"outputs":[{"name":"stdout","text":"Downloaded model folder: /kaggle/input/roberta-emotion/pytorch/v1/1\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# inference_model = EmotionClassifier().to(device)\n# state_dict_path = f\"{model_folder}/model.pth\"\n\n# inference_model.load_state_dict(torch.load(state_dict_path, map_location=device))\n# inference_model.eval()\n\n# print(\"Model loaded for inference!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:24:29.518466Z","iopub.execute_input":"2025-11-30T06:24:29.518964Z","iopub.status.idle":"2025-11-30T06:24:33.295613Z","shell.execute_reply.started":"2025-11-30T06:24:29.518940Z","shell.execute_reply":"2025-11-30T06:24:33.294809Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded for inference!\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n\n# test_ds  = EmotionDataset(test, tokenizer, is_train=False)\n# test_loader  = DataLoader(test_ds, batch_size=16, shuffle=False)\n\n\n# final_preds = []\n\n# with torch.no_grad():\n#     for batch in test_loader:\n#         input_ids, attention_mask = [b.to(device) for b in batch]\n#         outputs = inference_model(input_ids, attention_mask)\n#         probs = torch.sigmoid(outputs).cpu().numpy()\n#         preds = (probs > 0.5).astype(int)\n#         final_preds.append(preds)\n\n# final_preds = np.vstack(final_preds)\n\n\n\n# submission = pd.DataFrame({\n#     \"id\": test[\"id\"],\n#     \"anger\": final_preds[:, 0],\n#     \"fear\": final_preds[:, 1],\n#     \"joy\": final_preds[:, 2],\n#     \"sadness\": final_preds[:, 3],\n#     \"surprise\": final_preds[:, 4],\n# })\n\n# submission.to_csv(\"submission.csv\", index=False)\n# submission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:24:36.804642Z","iopub.execute_input":"2025-11-30T06:24:36.805187Z","iopub.status.idle":"2025-11-30T06:24:48.511721Z","shell.execute_reply.started":"2025-11-30T06:24:36.805160Z","shell.execute_reply":"2025-11-30T06:24:48.510934Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"   id  anger  fear  joy  sadness  surprise\n0   0      1     1    0        0         0\n1   1      0     0    0        0         0\n2   2      1     1    0        0         1\n3   3      0     1    0        0         0\n4   4      0     1    0        0         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anger</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# **MODEL FROM SCRATCH**","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# import re\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n# from sklearn.model_selection import StratifiedKFold\n# from sklearn.metrics import f1_score\n# from collections import Counter\n# from tqdm.auto import tqdm\n# import warnings\n# warnings.filterwarnings('ignore')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:06:14.064735Z","iopub.execute_input":"2025-11-30T16:06:14.065016Z","iopub.status.idle":"2025-11-30T16:06:14.069563Z","shell.execute_reply.started":"2025-11-30T16:06:14.064997Z","shell.execute_reply":"2025-11-30T16:06:14.069011Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# class Config:\n#     # Model architecture\n#     VOCAB_SIZE = 30000          # Increased vocabulary\n#     EMBEDDING_DIM = 400         # Larger embeddings\n#     HIDDEN_DIM = 512            # Larger hidden size\n#     NUM_LAYERS = 3              # More layers\n#     NUM_LABELS = 5\n#     DROPOUT = 0.4               # Adjusted dropout\n#     BIDIRECTIONAL = True\n    \n#     # Training settings\n#     BATCH_SIZE = 32             # Smaller batch for better gradients\n#     EPOCHS = 20                 # More epochs\n#     LEARNING_RATE = 0.0015      # Adjusted learning rate\n#     MAX_LENGTH = 150            # Longer sequences\n#     WEIGHT_DECAY = 1e-5         # L2 regularization\n    \n#     # Augmentation\n#     USE_AUGMENTATION = True\n#     AUG_PROBABILITY = 0.3\n    \n#     # Other settings\n#     SEED = 42\n#     DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#     EMOTION_COLS = ['anger', 'fear', 'joy', 'sadness', 'surprise']\n\n# def set_seed(seed=42):\n#     np.random.seed(seed)\n#     torch.manual_seed(seed)\n#     if torch.cuda.is_available():\n#         torch.cuda.manual_seed_all(seed)\n\n# set_seed(Config.SEED)\n# print(f\"Using device: {Config.DEVICE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:06:16.241215Z","iopub.execute_input":"2025-11-30T16:06:16.241958Z","iopub.status.idle":"2025-11-30T16:06:16.248686Z","shell.execute_reply.started":"2025-11-30T16:06:16.241934Z","shell.execute_reply":"2025-11-30T16:06:16.248135Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# wandb.login(key = \"1cae1eb0b3009c258573b649b577124df891befe\" , relogin=True) \n\n# wandb.init(\n#     project=\"23f1001420-t32025\",\n#     name=\"scratch_emotion_classifier\",\n#     config={\n#         \"vocab_size\": Config.VOCAB_SIZE,\n#         \"embedding_dim\": Config.EMBEDDING_DIM,\n#         \"hidden_dim\": Config.HIDDEN_DIM,\n#         \"num_layers\": Config.NUM_LAYERS,\n#         \"num_labels\": Config.NUM_LABELS,\n#         \"dropout\": Config.DROPOUT,\n#         \"bidirectional\": Config.BIDIRECTIONAL,\n        \n#         \"batch_size\": Config.BATCH_SIZE,\n#         \"epochs\": Config.EPOCHS,\n#         \"learning_rate\": Config.LEARNING_RATE,\n#         \"max_length\": Config.MAX_LENGTH,\n#         \"weight_decay\": Config.WEIGHT_DECAY,\n        \n#         \"augmentation\": Config.USE_AUGMENTATION,\n#         \"aug_prob\": Config.AUG_PROBABILITY,\n        \n#         \"seed\": Config.SEED,\n#     }\n# )\n\n# config = wandb.config\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:06:18.739304Z","iopub.execute_input":"2025-11-30T16:06:18.739826Z","iopub.status.idle":"2025-11-30T16:06:25.552432Z","shell.execute_reply.started":"2025-11-30T16:06:18.739804Z","shell.execute_reply":"2025-11-30T16:06:25.551877Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251130_160618-cvuh2rp6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/cvuh2rp6' target=\"_blank\">scratch_emotion_classifier</a></strong> to <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/cvuh2rp6' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/cvuh2rp6</a>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# # ============================================================================\n# # ENHANCED TEXT PREPROCESSING WITH AUGMENTATION\n# # ============================================================================\n\n# class EnhancedTextPreprocessor:\n#     def __init__(self):\n#         self.word2idx = {'<PAD>': 0, '<UNK>': 1}\n#         self.idx2word = {0: '<PAD>', 1: '<UNK>'}\n#         self.vocab_size = 2\n        \n#         # Emotion-specific keywords for better understanding\n#         self.emotion_keywords = {\n#             'anger': ['angry', 'mad', 'furious', 'annoyed', 'irritated', 'rage'],\n#             'fear': ['scared', 'afraid', 'terrified', 'anxious', 'worried', 'nervous'],\n#             'joy': ['happy', 'joyful', 'excited', 'glad', 'delighted', 'cheerful'],\n#             'sadness': ['sad', 'depressed', 'unhappy', 'miserable', 'heartbroken', 'crying'],\n#             'surprise': ['surprised', 'shocked', 'amazed', 'astonished', 'unexpected']\n#         }\n    \n#     def clean_text(self, text):\n#         \"\"\"Enhanced text cleaning\"\"\"\n#         text = str(text).lower()\n        \n#         # Preserve important punctuation\n#         text = re.sub(r'!+', ' ! ', text)\n#         text = re.sub(r'\\?+', ' ? ', text)\n        \n#         # Remove URLs\n#         text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n        \n#         # Handle negations\n#         text = re.sub(r\"n't\", \" not\", text)\n#         text = re.sub(r\"'m\", \" am\", text)\n#         text = re.sub(r\"'re\", \" are\", text)\n#         text = re.sub(r\"'ve\", \" have\", text)\n        \n#         # Remove mentions but keep hashtag content\n#         text = re.sub(r'@\\w+', '', text)\n#         text = re.sub(r'#', '', text)\n        \n#         # Keep letters, numbers, and some punctuation\n#         text = re.sub(r'[^a-z0-9\\s.,!?\\'-]', '', text)\n        \n#         # Handle repeated characters (e.g., 'soooo' -> 'so')\n#         text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n        \n#         # Remove extra whitespace\n#         text = re.sub(r'\\s+', ' ', text).strip()\n        \n#         return text\n    \n#     def tokenize(self, text):\n#         \"\"\"Enhanced tokenization\"\"\"\n#         return text.split()\n    \n#     def augment_text(self, text):\n#         \"\"\"Simple augmentation: synonym replacement\"\"\"\n#         words = text.split()\n#         if len(words) < 3 or np.random.random() > Config.AUG_PROBABILITY:\n#             return text\n        \n#         # Simple word dropout\n#         if np.random.random() < 0.3:\n#             idx = np.random.randint(0, len(words))\n#             words.pop(idx)\n        \n#         return ' '.join(words)\n    \n#     def build_vocab(self, texts, max_vocab_size=30000):\n#         \"\"\"Build vocabulary from texts\"\"\"\n#         print(\"Building vocabulary...\")\n#         word_freq = Counter()\n        \n#         for text in tqdm(texts):\n#             cleaned = self.clean_text(text)\n#             tokens = self.tokenize(cleaned)\n#             word_freq.update(tokens)\n        \n#         # Add most common words to vocabulary\n#         most_common = word_freq.most_common(max_vocab_size - 2)\n        \n#         for word, freq in most_common:\n#             if word not in self.word2idx:\n#                 self.word2idx[word] = self.vocab_size\n#                 self.idx2word[self.vocab_size] = word\n#                 self.vocab_size += 1\n        \n#         print(f\"Vocabulary size: {self.vocab_size}\")\n#         return self.word2idx\n    \n#     def text_to_sequence(self, text, max_length=150):\n#         \"\"\"Convert text to sequence of indices\"\"\"\n#         cleaned = self.clean_text(text)\n#         tokens = self.tokenize(cleaned)\n        \n#         # Convert to indices\n#         sequence = [self.word2idx.get(token, 1) for token in tokens]\n        \n#         # Pad or truncate\n#         if len(sequence) < max_length:\n#             sequence = sequence + [0] * (max_length - len(sequence))\n#         else:\n#             sequence = sequence[:max_length]\n        \n#         return sequence\n    \n#     def texts_to_sequences(self, texts, max_length=150):\n#         \"\"\"Convert multiple texts to sequences\"\"\"\n#         sequences = []\n#         for text in tqdm(texts, desc=\"Converting texts\"):\n#             sequences.append(self.text_to_sequence(text, max_length))\n#         return np.array(sequences)\n\n# # ============================================================================\n# # DATASET CLASS WITH AUGMENTATION\n# # ============================================================================\n\n# class EmotionDataset(Dataset):\n#     def __init__(self, sequences, labels, augment=False):\n#         self.sequences = torch.LongTensor(sequences)\n#         self.labels = torch.FloatTensor(labels)\n#         self.augment = augment\n    \n#     def __len__(self):\n#         return len(self.sequences)\n    \n#     def __getitem__(self, idx):\n#         sequence = self.sequences[idx]\n        \n#         # Simple sequence augmentation: random dropout\n#         if self.augment and np.random.random() < 0.2:\n#             mask = torch.rand(sequence.shape) > 0.1\n#             sequence = sequence * mask.long()\n        \n#         return {\n#             'sequence': sequence,\n#             'labels': self.labels[idx]\n#         }\n\n# # ============================================================================\n# # ENHANCED ATTENTION MECHANISM\n# # ============================================================================\n\n# class MultiHeadAttention(nn.Module):\n#     def __init__(self, hidden_dim, num_heads=4):\n#         super(MultiHeadAttention, self).__init__()\n#         self.num_heads = num_heads\n#         self.hidden_dim = hidden_dim\n#         self.head_dim = hidden_dim // num_heads\n        \n#         self.query = nn.Linear(hidden_dim, hidden_dim)\n#         self.key = nn.Linear(hidden_dim, hidden_dim)\n#         self.value = nn.Linear(hidden_dim, hidden_dim)\n#         self.out = nn.Linear(hidden_dim, hidden_dim)\n        \n#     def forward(self, x):\n#         batch_size, seq_len, hidden_dim = x.size()\n        \n#         # Linear projections\n#         Q = self.query(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n#         K = self.key(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n#         V = self.value(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        \n#         # Attention scores\n#         scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)\n#         attention_weights = F.softmax(scores, dim=-1)\n        \n#         # Apply attention\n#         attended = torch.matmul(attention_weights, V)\n#         attended = attended.transpose(1, 2).contiguous().view(batch_size, seq_len, hidden_dim)\n        \n#         output = self.out(attended)\n#         return output\n\n# # ============================================================================\n# # ENHANCED MODEL ARCHITECTURE\n# # ============================================================================\n\n# class EnhancedEmotionClassifier(nn.Module):\n#     def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, \n#                  num_labels, dropout=0.4, bidirectional=True):\n#         super(EnhancedEmotionClassifier, self).__init__()\n        \n#         self.hidden_dim = hidden_dim\n#         self.num_layers = num_layers\n#         self.bidirectional = bidirectional\n        \n#         # Embedding layer with dropout\n#         self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n#         self.embedding_dropout = nn.Dropout(0.2)\n        \n#         # GRU layers (often better than LSTM for text)\n#         self.gru = nn.GRU(\n#             embedding_dim,\n#             hidden_dim,\n#             num_layers,\n#             batch_first=True,\n#             dropout=dropout if num_layers > 1 else 0,\n#             bidirectional=bidirectional\n#         )\n        \n#         # Multi-head attention\n#         gru_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n#         self.attention = MultiHeadAttention(gru_output_dim, num_heads=4)\n        \n#         # Global max pooling\n#         self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n        \n#         # Feature combination\n#         combined_dim = gru_output_dim * 2  # attention + max pool\n        \n#         # Enhanced fully connected layers\n#         self.fc1 = nn.Linear(combined_dim, hidden_dim)\n#         self.bn1 = nn.BatchNorm1d(hidden_dim)\n#         self.dropout1 = nn.Dropout(dropout)\n        \n#         self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n#         self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n#         self.dropout2 = nn.Dropout(dropout)\n        \n#         self.fc3 = nn.Linear(hidden_dim // 2, hidden_dim // 4)\n#         self.bn3 = nn.BatchNorm1d(hidden_dim // 4)\n#         self.dropout3 = nn.Dropout(dropout)\n        \n#         self.fc_out = nn.Linear(hidden_dim // 4, num_labels)\n        \n#     def forward(self, x):\n#         # Embedding\n#         embedded = self.embedding(x)\n#         embedded = self.embedding_dropout(embedded)\n        \n#         # GRU\n#         gru_out, _ = self.gru(embedded)\n        \n#         # Multi-head attention\n#         attended = self.attention(gru_out)\n        \n#         # Mean of attended output\n#         attended_mean = torch.mean(attended, dim=1)\n        \n#         # Max pooling over sequence\n#         max_pooled = self.global_max_pool(gru_out.transpose(1, 2)).squeeze(2)\n        \n#         # Combine features\n#         combined = torch.cat([attended_mean, max_pooled], dim=1)\n        \n#         # Fully connected layers\n#         x = self.fc1(combined)\n#         x = self.bn1(x)\n#         x = F.relu(x)\n#         x = self.dropout1(x)\n        \n#         x = self.fc2(x)\n#         x = self.bn2(x)\n#         x = F.relu(x)\n#         x = self.dropout2(x)\n        \n#         x = self.fc3(x)\n#         x = self.bn3(x)\n#         x = F.relu(x)\n#         x = self.dropout3(x)\n        \n#         logits = self.fc_out(x)\n        \n#         return logits\n\n# # ============================================================================\n# # FOCAL LOSS FOR IMBALANCED DATA\n# # ============================================================================\n\n# class FocalLoss(nn.Module):\n#     def __init__(self, alpha=0.25, gamma=2.0):\n#         super(FocalLoss, self).__init__()\n#         self.alpha = alpha\n#         self.gamma = gamma\n        \n#     def forward(self, inputs, targets):\n#         BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n#         pt = torch.exp(-BCE_loss)\n#         F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n#         return F_loss.mean()\n\n# # ============================================================================\n# # TRAINING & EVALUATION FUNCTIONS\n# # ============================================================================\n\n# def train_epoch(model, data_loader, optimizer, criterion, device):\n#     model.train()\n#     losses = []\n    \n#     progress_bar = tqdm(data_loader, desc='Training')\n    \n#     for batch in progress_bar:\n#         sequences = batch['sequence'].to(device)\n#         labels = batch['labels'].to(device)\n        \n#         optimizer.zero_grad()\n        \n#         logits = model(sequences)\n#         loss = criterion(logits, labels)\n        \n#         loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n#         optimizer.step()\n        \n#         losses.append(loss.item())\n#         progress_bar.set_postfix({'loss': np.mean(losses)})\n    \n#     return np.mean(losses)\n\n# def eval_model(model, data_loader, criterion, device, threshold=0.5):\n#     model.eval()\n#     losses = []\n#     all_predictions = []\n#     all_labels = []\n    \n#     with torch.no_grad():\n#         for batch in tqdm(data_loader, desc='Evaluating'):\n#             sequences = batch['sequence'].to(device)\n#             labels = batch['labels'].to(device)\n            \n#             logits = model(sequences)\n#             loss = criterion(logits, labels)\n            \n#             losses.append(loss.item())\n            \n#             probs = torch.sigmoid(logits)\n#             preds = (probs > threshold).int()\n            \n#             all_predictions.extend(preds.cpu().numpy())\n#             all_labels.extend(labels.cpu().numpy())\n    \n#     all_predictions = np.array(all_predictions)\n#     all_labels = np.array(all_labels)\n    \n#     f1_macro = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n#     f1_per_class = f1_score(all_labels, all_predictions, average=None, zero_division=0)\n    \n#     return np.mean(losses), f1_macro, f1_per_class\n\n# def predict(model, data_loader, device, threshold=0.5):\n#     model.eval()\n#     all_predictions = []\n    \n#     with torch.no_grad():\n#         for batch in tqdm(data_loader, desc='Predicting'):\n#             sequences = batch['sequence'].to(device)\n            \n#             logits = model(sequences)\n#             probs = torch.sigmoid(logits)\n#             preds = (probs > threshold).int()\n            \n#             all_predictions.extend(preds.cpu().numpy())\n    \n#     return np.array(all_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:06:33.672897Z","iopub.execute_input":"2025-11-30T16:06:33.673502Z","iopub.status.idle":"2025-11-30T16:06:33.702677Z","shell.execute_reply.started":"2025-11-30T16:06:33.673480Z","shell.execute_reply":"2025-11-30T16:06:33.701906Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# # ============================================================================\n# # LOAD AND PREPARE DATA\n# # ============================================================================\n\n# print(\"Loading data...\")\n# train_df = pd.read_csv('/kaggle/input/2025-sep-dl-gen-ai-project/train.csv')\n\n# print(f\"Train shape: {train_df.shape}\")\n# print(f\"\\nFirst few rows:\")\n# print(train_df.head())\n\n# print(\"\\nEmotion distribution:\")\n# for col in Config.EMOTION_COLS:\n#     print(f\"{col}: {train_df[col].sum()} ({train_df[col].mean()*100:.2f}%)\")\n\n# # Initialize preprocessor\n# preprocessor = EnhancedTextPreprocessor()\n\n# # Build vocabulary\n# preprocessor.build_vocab(train_df['text'].tolist(), max_vocab_size=Config.VOCAB_SIZE)\n\n# # Convert texts to sequences\n# print(\"\\nConverting texts to sequences...\")\n# sequences = preprocessor.texts_to_sequences(\n#     train_df['text'].tolist(), \n#     max_length=Config.MAX_LENGTH\n# )\n\n# labels = train_df[Config.EMOTION_COLS].values\n\n# # Split data with stratification\n# train_seq, val_seq, train_labels, val_labels = train_test_split(\n#     sequences, labels, test_size=0.15, random_state=Config.SEED\n# )\n\n# print(f\"\\nTrain size: {len(train_seq)}\")\n# print(f\"Validation size: {len(val_seq)}\")\n\n# # Create datasets\n# train_dataset = EmotionDataset(train_seq, train_labels, augment=Config.USE_AUGMENTATION)\n# val_dataset = EmotionDataset(val_seq, val_labels, augment=False)\n\n# train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n# val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n\n# # ============================================================================\n# # INITIALIZE MODEL\n# # ============================================================================\n\n# print(\"\\nInitializing enhanced model...\")\n# model = EnhancedEmotionClassifier(\n#     vocab_size=preprocessor.vocab_size,\n#     embedding_dim=Config.EMBEDDING_DIM,\n#     hidden_dim=Config.HIDDEN_DIM,\n#     num_layers=Config.NUM_LAYERS,\n#     num_labels=Config.NUM_LABELS,\n#     dropout=Config.DROPOUT,\n#     bidirectional=Config.BIDIRECTIONAL\n# )\n# model.to(Config.DEVICE)\n\n# total_params = sum(p.numel() for p in model.parameters())\n# trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n# print(f\"Total parameters: {total_params:,}\")\n# print(f\"Trainable parameters: {trainable_params:,}\")\n\n# # Use Focal Loss for better handling of class imbalance\n# criterion = FocalLoss(alpha=0.25, gamma=2.0)\n# optimizer = torch.optim.AdamW(\n#     model.parameters(), \n#     lr=Config.LEARNING_RATE,\n#     weight_decay=Config.WEIGHT_DECAY\n# )\n# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n#     optimizer, T_0=5, T_mult=2\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:06:40.136913Z","iopub.execute_input":"2025-11-30T16:06:40.137268Z","iopub.status.idle":"2025-11-30T16:06:40.831316Z","shell.execute_reply.started":"2025-11-30T16:06:40.137245Z","shell.execute_reply":"2025-11-30T16:06:40.830729Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nTrain shape: (6827, 8)\n\nFirst few rows:\n   id                                               text  anger  fear  joy  \\\n0   0  the dentist that did the work apparently did a...      1     0    0   \n1   1  i'm gonna absolutely ~~suck~~ be terrible duri...      0     1    0   \n2   2  bridge: so leave me drowning calling houston, ...      0     1    0   \n3   3  after that mess i went to see my now ex-girlfr...      1     1    0   \n4   4  as he stumbled i ran off, afraid it might some...      0     1    0   \n\n   sadness  surprise                    emotions  \n0        1         0         ['anger' 'sadness']  \n1        1         0          ['fear' 'sadness']  \n2        1         0          ['fear' 'sadness']  \n3        1         0  ['anger' 'fear' 'sadness']  \n4        0         0                    ['fear']  \n\nEmotion distribution:\nanger: 808 (11.84%)\nfear: 3860 (56.54%)\njoy: 1660 (24.32%)\nsadness: 2171 (31.80%)\nsurprise: 1999 (29.28%)\nBuilding vocabulary...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6827 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02902893b3934abdb63bee9f005bfa82"}},"metadata":{}},{"name":"stdout","text":"Vocabulary size: 11092\n\nConverting texts to sequences...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Converting texts:   0%|          | 0/6827 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6db7849331a6442780af676b59b25fef"}},"metadata":{}},{"name":"stdout","text":"\nTrain size: 5802\nValidation size: 1025\n\nInitializing enhanced model...\nTotal parameters: 22,108,229\nTrainable parameters: 22,108,229\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# # ============================================================================\n# # TRAINING LOOP\n# # ============================================================================\n\n# print(\"\\n\" + \"=\"*60)\n# print(\"STARTING TRAINING\")\n# print(\"=\"*60)\n\n# best_f1 = 0\n# patience_counter = 0\n# patience = 5\n\n# history = {'train_loss': [], 'val_loss': [], 'val_f1': []}\n\n# for epoch in range(Config.EPOCHS):\n#     print(f'\\nEpoch {epoch + 1}/{Config.EPOCHS}')\n#     print('-' * 60)\n    \n#     train_loss = train_epoch(model, train_loader, optimizer, criterion, Config.DEVICE)\n#     val_loss, val_f1, val_f1_per_class = eval_model(model, val_loader, criterion, Config.DEVICE)\n    \n#     scheduler.step()\n    \n#     history['train_loss'].append(train_loss)\n#     history['val_loss'].append(val_loss)\n#     history['val_f1'].append(val_f1)\n\n#     wandb.log({\n#         \"train_loss\": train_loss,\n#         \"val_loss\": val_loss,\n#         \"val_f1\": val_f1,\n#         \"learning_rate\": optimizer.param_groups[0]['lr']\n#     })\n    \n#     print(f'\\nTrain Loss: {train_loss:.4f}')\n#     print(f'Val Loss: {val_loss:.4f}')\n#     print(f'Val Macro F1: {val_f1:.4f}')\n#     print(f'\\nPer-class F1 scores:')\n#     for emotion, f1 in zip(Config.EMOTION_COLS, val_f1_per_class):\n#         wandb.log({f\"F1_{emotion}\": f1})\n#         print(f'  {emotion}: {f1:.4f}')\n    \n#     # Save best model\n#     if val_f1 > best_f1:\n#         best_f1 = val_f1\n#         patience_counter = 0\n#         torch.save({\n#             'model_state_dict': model.state_dict(),\n#             'preprocessor': preprocessor,\n#             'config': Config\n#         }, 'best_model.pt')\n#         print(f'\\n✓ New best model saved! (F1: {best_f1:.4f})')\n#     else:\n#         patience_counter += 1\n#         if patience_counter >= patience:\n#             print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n#             break\n\n# print(\"\\n\" + \"=\"*60)\n# print(f\"TRAINING COMPLETED - Best F1: {best_f1:.4f}\")\n# print(\"=\"*60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:06:45.615891Z","iopub.execute_input":"2025-11-30T16:06:45.616530Z","iopub.status.idle":"2025-11-30T16:19:50.227763Z","shell.execute_reply.started":"2025-11-30T16:06:45.616506Z","shell.execute_reply":"2025-11-30T16:19:50.227204Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSTARTING TRAINING\n============================================================\n\nEpoch 1/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f112be73fdf346ef84fcf6f35903824f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a2d790dd8f14b48b3cfe08b3dec2ed9"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0401\nVal Loss: 0.0362\nVal Macro F1: 0.1632\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.6723\n  joy: 0.0000\n  sadness: 0.1439\n  surprise: 0.0000\n\n✓ New best model saved! (F1: 0.1632)\n\nEpoch 2/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff00d509ea094cefa1336f74f2a28eb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3d3fc9ffa9d4ba380f9d38a826277ab"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0369\nVal Loss: 0.0360\nVal Macro F1: 0.1434\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7171\n  joy: 0.0000\n  sadness: 0.0000\n  surprise: 0.0000\n\nEpoch 3/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fa6aaef7fc44d0280b8579e3da0e7ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74ce8d83a5f84383afa1c6b54b31bd16"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0360\nVal Loss: 0.0360\nVal Macro F1: 0.1721\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7171\n  joy: 0.0000\n  sadness: 0.0000\n  surprise: 0.1433\n\n✓ New best model saved! (F1: 0.1721)\n\nEpoch 4/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cba151e75e7f418486373b99136b9695"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e3ab9441e164da6bb539077a9d60162"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0356\nVal Loss: 0.0351\nVal Macro F1: 0.2455\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7106\n  joy: 0.0000\n  sadness: 0.0000\n  surprise: 0.5168\n\n✓ New best model saved! (F1: 0.2455)\n\nEpoch 5/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e82dd37118be4944870edb4d82b468e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0e667440ed5456abcd6fce9813813b1"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0350\nVal Loss: 0.0349\nVal Macro F1: 0.2506\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7061\n  joy: 0.0000\n  sadness: 0.0000\n  surprise: 0.5467\n\n✓ New best model saved! (F1: 0.2506)\n\nEpoch 6/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4be01462d26a4f09888e2d48fa887f7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40bad780bc89485e959a1117f7645216"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0353\nVal Loss: 0.0350\nVal Macro F1: 0.3150\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7143\n  joy: 0.0000\n  sadness: 0.2761\n  surprise: 0.5847\n\n✓ New best model saved! (F1: 0.3150)\n\nEpoch 7/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cafb2ab702b45c58fc4e32763019751"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b41ec4e4c00647858d6e5fe0956deea7"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0342\nVal Loss: 0.0350\nVal Macro F1: 0.2845\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7167\n  joy: 0.0000\n  sadness: 0.2469\n  surprise: 0.4592\n\nEpoch 8/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e5b1368a0a24545822a9358d91ff409"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0867da3c10334b6782c25269e523ba1e"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0329\nVal Loss: 0.0342\nVal Macro F1: 0.2807\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.6896\n  joy: 0.0000\n  sadness: 0.0937\n  surprise: 0.6203\n\nEpoch 9/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2380d30fa7ed4e2b91dd54d31f98b996"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14524a153e304d1ba447addbf1fb9215"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0311\nVal Loss: 0.0325\nVal Macro F1: 0.3360\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.6814\n  joy: 0.0000\n  sadness: 0.3583\n  surprise: 0.6400\n\n✓ New best model saved! (F1: 0.3360)\n\nEpoch 10/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4aed64dfe1d4c4da61debbd3999ffa9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4a1ba3dd6b34d9f8912ca60560a9c81"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0292\nVal Loss: 0.0322\nVal Macro F1: 0.4020\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.6766\n  joy: 0.2222\n  sadness: 0.4583\n  surprise: 0.6528\n\n✓ New best model saved! (F1: 0.4020)\n\nEpoch 11/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77618d3e612e4fc9b7f7550e781f01c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09b1afc356874f8ca05e60276a96205a"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0269\nVal Loss: 0.0315\nVal Macro F1: 0.4503\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.6988\n  joy: 0.4190\n  sadness: 0.4353\n  surprise: 0.6984\n\n✓ New best model saved! (F1: 0.4503)\n\nEpoch 12/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d53589f043d84413b74b154912e6eedf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15a0a51af8db445da3c4e94fc15d9fd9"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0250\nVal Loss: 0.0306\nVal Macro F1: 0.4788\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7243\n  joy: 0.5259\n  sadness: 0.4597\n  surprise: 0.6839\n\n✓ New best model saved! (F1: 0.4788)\n\nEpoch 13/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9249659542614011b971b9087033ee47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3e903756b904e07bfe2ea2cb589f6c8"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0232\nVal Loss: 0.0304\nVal Macro F1: 0.4957\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7204\n  joy: 0.5763\n  sadness: 0.4684\n  surprise: 0.7133\n\n✓ New best model saved! (F1: 0.4957)\n\nEpoch 14/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"277716aa3bd9496e95ccb091d8700869"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f98cb3a89734248bbb840e1aab2ea51"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0220\nVal Loss: 0.0309\nVal Macro F1: 0.4857\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7288\n  joy: 0.5610\n  sadness: 0.4292\n  surprise: 0.7096\n\nEpoch 15/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33859bb1cd9c48deb1e0038c85544a68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c598167c07764795811782b6430ed3f2"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0213\nVal Loss: 0.0304\nVal Macro F1: 0.5046\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7438\n  joy: 0.5799\n  sadness: 0.4789\n  surprise: 0.7205\n\n✓ New best model saved! (F1: 0.5046)\n\nEpoch 16/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f30a554722bb456bb1f07dd85848f8da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf0835b25bd6455b8d38ead7ebceb34a"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0243\nVal Loss: 0.0354\nVal Macro F1: 0.4325\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.6318\n  joy: 0.5076\n  sadness: 0.3540\n  surprise: 0.6688\n\nEpoch 17/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64c57128094e4f6491ec03706c4bba2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b5ca7e7733d49b897d7447f3aa03ff6"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0243\nVal Loss: 0.0306\nVal Macro F1: 0.4931\n\nPer-class F1 scores:\n  anger: 0.0000\n  fear: 0.7091\n  joy: 0.5929\n  sadness: 0.4879\n  surprise: 0.6757\n\nEpoch 18/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9723bcbf06634d84af9f40a21e884c2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a5819c432844f20b518712afd23d2f3"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0223\nVal Loss: 0.0305\nVal Macro F1: 0.5417\n\nPer-class F1 scores:\n  anger: 0.0966\n  fear: 0.7640\n  joy: 0.5940\n  sadness: 0.5348\n  surprise: 0.7191\n\n✓ New best model saved! (F1: 0.5417)\n\nEpoch 19/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"898c896ffdc246569b757ad000a24042"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"669b782102344a97a2c56c252f80e5ce"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0206\nVal Loss: 0.0298\nVal Macro F1: 0.5853\n\nPer-class F1 scores:\n  anger: 0.3152\n  fear: 0.7502\n  joy: 0.6337\n  sadness: 0.4903\n  surprise: 0.7370\n\n✓ New best model saved! (F1: 0.5853)\n\nEpoch 20/20\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ba07674ad94da490aae9d17763dc58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdff982d2d4e4152b21a44df11bfd6b7"}},"metadata":{}},{"name":"stdout","text":"\nTrain Loss: 0.0192\nVal Loss: 0.0295\nVal Macro F1: 0.6175\n\nPer-class F1 scores:\n  anger: 0.4444\n  fear: 0.7745\n  joy: 0.6256\n  sadness: 0.5574\n  surprise: 0.6854\n\n✓ New best model saved! (F1: 0.6175)\n\n============================================================\nTRAINING COMPLETED - Best F1: 0.6175\n============================================================\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:20:22.726960Z","iopub.execute_input":"2025-11-30T16:20:22.727573Z","iopub.status.idle":"2025-11-30T16:20:23.110930Z","shell.execute_reply.started":"2025-11-30T16:20:22.727547Z","shell.execute_reply":"2025-11-30T16:20:23.110319Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>F1_anger</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▆█</td></tr><tr><td>F1_fear</td><td>▃▅▅▅▅▅▅▄▃▃▄▆▅▆▆▁▅▇▇█</td></tr><tr><td>F1_joy</td><td>▁▁▁▁▁▁▁▁▁▃▆▇▇▇▇▇████</td></tr><tr><td>F1_sadness</td><td>▃▁▁▁▁▄▄▂▆▇▆▇▇▆▇▅▇█▇█</td></tr><tr><td>F1_surprise</td><td>▁▁▂▆▆▇▅▇▇▇█▇███▇▇███</td></tr><tr><td>learning_rate</td><td>▇▆▃▂██▇▇▆▄▃▂▂▁████▇▇</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▆▆▅▄▄▃▂▂▂▃▃▂▁▁</td></tr><tr><td>val_f1</td><td>▁▁▁▃▃▄▃▃▄▅▆▆▆▆▆▅▆▇██</td></tr><tr><td>val_loss</td><td>███▇▇▇▇▆▄▄▃▂▂▂▂▇▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>F1_anger</td><td>0.44444</td></tr><tr><td>F1_fear</td><td>0.77447</td></tr><tr><td>F1_joy</td><td>0.62557</td></tr><tr><td>F1_sadness</td><td>0.55738</td></tr><tr><td>F1_surprise</td><td>0.68539</td></tr><tr><td>learning_rate</td><td>0.00128</td></tr><tr><td>train_loss</td><td>0.01923</td></tr><tr><td>val_f1</td><td>0.61745</td></tr><tr><td>val_loss</td><td>0.0295</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">scratch_emotion_classifier</strong> at: <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/cvuh2rp6' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025/runs/cvuh2rp6</a><br> View project at: <a href='https://wandb.ai/dlproject_sept2025/23f1001420-t32025' target=\"_blank\">https://wandb.ai/dlproject_sept2025/23f1001420-t32025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251130_160618-cvuh2rp6/logs</code>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# import kagglehub\n# # torch.save(model.state_dict(), \"emotion_classifier.pth\")\n# torch.save({\n#     'model_state_dict': model.state_dict(),\n#     'preprocessor': preprocessor,\n#     'config': Config\n# }, 'best_model.pt')\n\n\n# # Upload to KaggleHub\n# user = \"somya2611\" \n# emotion_handle = f\"{user}/emotion-classifier/pyTorch/v1\"\n# os.makedirs(\"emotion_model_dir\", exist_ok=True)\n# os.rename(\"best_model.pt\", \"emotion_model_dir/best_model.pt\")\n# kagglehub.model_upload(emotion_handle, \"emotion_model_dir\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import kagglehub\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n# user = \"somya2611\" \n# emotion_handle = f\"{user}/emotion-classifier/pyTorch/v1\"\n\n# model_path = kagglehub.model_download(emotion_handle)\n\n# checkpoint = torch.load(f\"{model_path}/best_model.pt\", map_location=device, weights_only=False)\n\n\n\n# # Recreate model architecture\n# model = EnhancedEmotionClassifier(\n#     vocab_size=checkpoint['preprocessor'].vocab_size,\n#     embedding_dim=checkpoint['config'].EMBEDDING_DIM,\n#     hidden_dim=checkpoint['config'].HIDDEN_DIM,\n#     num_layers=checkpoint['config'].NUM_LAYERS,\n#     num_labels=checkpoint['config'].NUM_LABELS,\n#     dropout=checkpoint['config'].DROPOUT,\n#     bidirectional=checkpoint['config'].BIDIRECTIONAL\n# )\n\n# # Load trained weights\n# model.load_state_dict(checkpoint['model_state_dict'])\n# model.eval()\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# model.to(device)\n\n# # Get preprocessor\n# preprocessor = checkpoint['preprocessor']\n\n# # Load test data\n# test_df = pd.read_csv('/kaggle/input/2025-sep-dl-gen-ai-project/test.csv')\n\n# # Process and predict\n# test_sequences = preprocessor.texts_to_sequences(\n#     test_df['text'].tolist(),\n#     max_length=checkpoint['config'].MAX_LENGTH\n# )\n\n# # Create dataset and loader\n# test_labels_dummy = torch.zeros((len(test_sequences), 5))\n# test_dataset = EmotionDataset(test_sequences, test_labels_dummy, augment=False)\n# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n\n# # Predict\n# predictions = predict(model, test_loader, device, threshold=0.5)\n\n# # Create submission\n# submission = pd.DataFrame(predictions, columns=['anger', 'fear', 'joy', 'sadness', 'surprise'])\n# if 'id' in test_df.columns:\n#     submission.insert(0, 'id', test_df['id'])\n# submission.to_csv('submission.csv', index=False)\n# print(\"Predictions saved!\")\n\n# print(submission.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}